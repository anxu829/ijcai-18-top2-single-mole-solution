{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.数据的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意，一般需要对于数据进行统一处理\n",
    "train = pd.read_csv('../data/round2_train.txt', sep=' ',nrows=100)\n",
    "testa = pd.read_csv('../data/round2_ijcai_18_test_a_20180425.txt', sep=' ',nrows=100)\n",
    "testb = pd.read_csv('../data/round2_ijcai_18_test_b_20180510.txt', sep=' ',nrows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据的预处理\n",
    "#### 2.1 为testa，b统一添加 is_trade 变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa['is_trade'] = -1\n",
    "testb['is_trade'] = -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 生成test 数据集和data全量数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat([testa,testb])\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 日期处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 时间戳处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def today(x):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 日期和小时特征抽取\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getday(x):\n",
    "    day=int(x.split(' ')[0].split('-')[-1])\n",
    "    if day==31:\n",
    "        day=0\n",
    "    return day\n",
    "\n",
    "def gethour(x):\n",
    "    # 总的来说，这里的处理是把时间单位细化了，用48 ‘hour’来记录一天，\n",
    "    # 所以对于比如 0:00 0:30 1:00 会记录为 0:00 1:00 2:00\n",
    "    hour=int(x.split(' ')[1].split(':')[0])    #  从 2018-09-06 21:58:20 获得 21\n",
    "    minute=int(x.split(' ')[1].split(':')[1])  #  从 2018-09-06 21:58:20 获得 58 \n",
    "    minute=1 if minute>=30 else 0              #  后半个小时记加 1 \n",
    "    return hour*2+minute                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3 提取日期和时间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "data['day']=data['context_timestamp'].apply(lambda x:getday(today(x))) # 提取了日期信息\n",
    "data['hour']=data['context_timestamp'].apply(lambda x:int(today(x).split()[1].split(':')[0])) # 提取了小时信息\n",
    "\n",
    "data['context_timestamp']=data['context_timestamp'].apply(lambda x:today(x)) # 把时间戳转化为 2018-09-06 21:58:20\n",
    "data['hour48']=data['context_timestamp'].apply(gethour) # 具体操作请看 gethour 注释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 对query的预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 首先来展示下数据\n",
    "- 类别：商品具有的类别 【注】这里的问题，类别是一个三级的结构，每个商品严格意义上只有一个类别\n",
    "- 属性：商品具有的属性 \n",
    "- 预测：认为商品是某些类别，并判断属性 【注】预测的类别不具有层级结构\n",
    "\n",
    "\n",
    "- item_category_list     \n",
    "```\n",
    "'836752724084922533;8769426218101861255'\n",
    "```\n",
    "- item_property_list\n",
    "```\n",
    "'7344985833148694227;6611726991947724280;7839592306500064003;9148482949976129397;2891682021882519203;6491818071284064879;8402837029054975192;4573204630033800991;296270104965272366;5512096939518377359;720840888466250585;7813953447682596156;3108863080117742654;2408002633983396839;2886347676380617486;6467463580352992420;8876749174447494343;834709706843352941;7420970629504412536;5293683912990614211;1111963465991721248;6314021851828608197;3600371705120228770;7078696387843273342;688979592902776162'\n",
    "```\n",
    "\n",
    "- predict_category_property \n",
    "```\n",
    "'8769426218101861255:-1;836752724084922533:3480876984427839465,5103206280374780290,1972069903722514407, \n",
    "2636395404473730413,3540471119339706981,6491818071284064879'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理1：判断预测的类别和真实类别重合的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_cate(x):\n",
    "    cate = set(x['item_category_list'].split(';'))                                            # 首先提取特征\n",
    "    cate2 = set([i.split(':')[0] for i in x['predict_category_property'].split(';')])         # 其次提取预测的特征\n",
    "    return len(cate & cate2)\n",
    "\n",
    "data['same_cate']=data.apply(same_cate,axis=1) #相同类别数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['836752724084922533;8769426218101861255',\n",
       "       '836752724084922533;6670526099037031245',\n",
       "       '836752724084922533;6693726201323251689'], dtype=object)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.item_category_list.head().values[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理2：提取预测的属性和真实属性的重合个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_property(x):\n",
    "    \n",
    "    property_a = set(x['item_property_list'].split(';')) # 获取属性\n",
    "    \n",
    "    # 获得属性比较困难，因为有的类别的属性为 -1\n",
    "    # predict 字段的形式\n",
    "    # '8769426218101861255:-1;836752724084922533:3480876984427839465,5103206280374780290,1972069903722514407, 2636395404473730413,3540471119339706981,6491818071284064879'\n",
    "    \n",
    "    # property_b : 拿到对商品预测的所有属性的去重结果 \n",
    "    a = []\n",
    "    for i in [i.split(':')[1].split(',') for i in x['predict_category_property'].split(';') if\n",
    "              len(i.split(':')) > 1]:\n",
    "        a += i\n",
    "    property_b = set(a)\n",
    "    \n",
    "    # 返回预测中的属性的个数\n",
    "    return len(property_a & property_b)\n",
    "\n",
    "data['same_property']=data.apply(same_property,axis=1) #相同属性数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理3  获取商品的属性数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['property_num']=data['item_property_list'].apply(lambda x:len(x.split(';'))) #属性的数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理4 获取query的类别的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pred_cate_num']=data['predict_category_property'].apply(lambda x:len(x.split(';'))) #query的类别数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理5  query的属性数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    try:\n",
    "        return len([i for i in reduce((lambda x, y: x + y), [i.split(':')[1].split(',') for i in x.split(';') if len(i.split(':'))>1]) if i != '-1'])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "data['pred_prop_num']=data['predict_category_property'].apply(f) #query的属性数目\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解释一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 在 \n",
      " [i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1]  \n",
      " 这一步获取了每个类别预测的属性数 : \n",
      " [['-1'], ['3480876984427839465', '5103206280374780290', '1972069903722514407', ' 2636395404473730413', '3540471119339706981', '6491818071284064879']]\n",
      "2 在 \n",
      "  [i for i in reduce((lambda x, y: x + y), [i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1]  ) if i != '-1'] \n",
      " 这一步把每个类目下预测的属性的list串联了起来 : \n",
      " ['3480876984427839465', '5103206280374780290', '1972069903722514407', ' 2636395404473730413', '3540471119339706981', '6491818071284064879']\n",
      "3 然后用len 统计了长度\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 解释一下：\n",
    "predict = '8769426218101861255:-1;836752724084922533:3480876984427839465,5103206280374780290,1972069903722514407, 2636395404473730413,3540471119339706981,6491818071284064879'\n",
    "print(\"1 在 \\n [i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1]  \\n 这一步获取了每个类别预测的属性数 : \\n\",[i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1])\n",
    "print(\"2 在 \\n\" ,\" [i for i in reduce((lambda x, y: x + y), [i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1]  ) if i != '-1'] \\n 这一步把每个类目下预测的属性的list串联了起来 : \\n\" , [i for i in reduce((lambda x, y: x + y), [i.split(':')[1].split(',') for i in predict.split(';') if len(i.split(':'))>1]  ) if i != '-1']  )\n",
    "print(\"3 然后用len 统计了长度\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query的第一个类别和所有类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8769426218101861255'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['query1']=data['predict_category_property'].apply(lambda x:x.split(';')[0].split(':')[0]) #query第一个类别\n",
    "data.query1.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query的所有类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['836752724084922533-8769426218101861255',\n",
       "       '1852600517265062354-6670526099037031245-836752724084922533'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['query']=data['predict_category_property'].apply(lambda x:'-'.join(sorted([i.split(':')[0] for i in [i for i in x.split(';')]]))) #query的全部类别\n",
    "data['query'].values[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 对category 的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取二级标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               836752724084922533;8769426218101861255\n",
       "1               836752724084922533;6670526099037031245\n",
       "2               836752724084922533;6693726201323251689\n",
       "3               836752724084922533;6670526099037031245\n",
       "4    836752724084922533;3613783563199627217;6370392...\n",
       "Name: item_category_list, dtype: object"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cate'] = data['item_category_list'].apply(lambda x: x.split(';')[1])\n",
    "data.item_category_list.head() # 注意到一级标签都是接近的,且注意到第二条数据二级类目和 query 结果一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 38 columns):\n",
      "instance_id                  300 non-null int64\n",
      "item_id                      300 non-null int64\n",
      "item_category_list           300 non-null object\n",
      "item_property_list           300 non-null object\n",
      "item_brand_id                300 non-null int64\n",
      "item_city_id                 300 non-null int64\n",
      "item_price_level             300 non-null int64\n",
      "item_sales_level             300 non-null int64\n",
      "item_collected_level         300 non-null int64\n",
      "item_pv_level                300 non-null int64\n",
      "user_id                      300 non-null int64\n",
      "user_gender_id               300 non-null int64\n",
      "user_age_level               300 non-null int64\n",
      "user_occupation_id           300 non-null int64\n",
      "user_star_level              300 non-null int64\n",
      "context_id                   300 non-null int64\n",
      "context_timestamp            300 non-null object\n",
      "context_page_id              300 non-null int64\n",
      "predict_category_property    300 non-null object\n",
      "shop_id                      300 non-null int64\n",
      "shop_review_num_level        300 non-null int64\n",
      "shop_review_positive_rate    300 non-null float64\n",
      "shop_star_level              300 non-null int64\n",
      "shop_score_service           300 non-null float64\n",
      "shop_score_delivery          300 non-null float64\n",
      "shop_score_description       300 non-null float64\n",
      "is_trade                     300 non-null int64\n",
      "day                          300 non-null int64\n",
      "hour                         300 non-null int64\n",
      "hour48                       300 non-null int64\n",
      "same_cate                    300 non-null int64\n",
      "same_property                300 non-null int64\n",
      "property_num                 300 non-null int64\n",
      "pred_cate_num                300 non-null int64\n",
      "pred_prop_num                300 non-null int64\n",
      "query1                       300 non-null object\n",
      "query                        300 non-null object\n",
      "cate                         300 non-null object\n",
      "dtypes: float64(4), int64(27), object(7)\n",
      "memory usage: 89.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_id\n",
      "item_id\n",
      "user_id\n",
      "item_brand_id\n",
      "item_city_id\n",
      "user_gender_id\n",
      "user_occupation_id\n",
      "context_page_id\n",
      "hour\n",
      "item_property_list\n",
      "predict_category_property\n",
      "day\n",
      "item_price_level\n",
      "item_sales_level\n",
      "item_collected_level\n",
      "item_pv_level\n",
      "user_age_level\n",
      "user_star_level\n",
      "shop_review_num_level\n",
      "shop_review_positive_rate\n",
      "shop_star_level\n",
      "shop_score_service\n",
      "shop_score_delivery\n",
      "shop_score_description\n",
      "context_page_id\n"
     ]
    }
   ],
   "source": [
    "def fillna(data):\n",
    "    # 对数值变量 和 字符变量 做处理 \n",
    "    numeric_feature = ['day', 'item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level',\n",
    "                       'user_age_level', 'user_star_level', 'shop_review_num_level',\n",
    "                       'shop_review_positive_rate', 'shop_star_level', 'shop_score_service', 'shop_score_delivery',\n",
    "                       'shop_score_description', 'context_page_id'\n",
    "                       ]\n",
    "    # 字符型数据\n",
    "    string_feature = ['shop_id', 'item_id', 'user_id', 'item_brand_id', 'item_city_id', 'user_gender_id',\n",
    "                      'user_occupation_id', 'context_page_id', 'hour']\n",
    "    other_feature = ['item_property_list', 'predict_category_property']\n",
    "    \n",
    "    #填充缺失值\n",
    "    # 这道题的关键：缺失值处的值为 -1 \n",
    "    for i in string_feature+other_feature:\n",
    "        # 使用众数填充缺失值\n",
    "        mode_num = data[i].mode()[0]\n",
    "        if (mode_num != -1):\n",
    "            print(i)\n",
    "            data.loc[data[i] == -1, i] = mode_num\n",
    "        else:\n",
    "            print(-1)\n",
    "    for i in numeric_feature:\n",
    "        # 使用均值填充缺失值\n",
    "        mean_num = data[i].mean()\n",
    "        if (mean_num != -1):\n",
    "            print(i)\n",
    "            data.loc[data[i] == -1, i] = mean_num\n",
    "        else:\n",
    "            print(-1)\n",
    "    return data\n",
    "data=fillna(data.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 对property feature的抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict finish\n",
      "top finish\n"
     ]
    }
   ],
   "source": [
    "def property_feature(org):\n",
    "    org = org.copy()\n",
    "    # 注意，这件事情只能对property 做， category 是有级联关系的\n",
    "    # 拿到所有的 item 属性信息 ， 注意是对于所有的样本的所有的属性信息\n",
    "    tmp=org['item_property_list'].apply(lambda x:x.split(';')).values\n",
    "    \n",
    "    # 拿到属性信息（字典）\n",
    "    property_dict={}\n",
    "    # 拿到属性信息 （list）\n",
    "    property_list=[]\n",
    "    \n",
    "    # 将所有的property_list 串联起来\n",
    "    for i in tmp:\n",
    "        property_list+=i\n",
    "    \n",
    "    # 统计所有出现过的property\n",
    "    for i in property_list:\n",
    "        if i in property_dict:\n",
    "            property_dict[i]+=1\n",
    "        else:\n",
    "            property_dict[i] = 1\n",
    "    \n",
    "    print('dict finish')\n",
    "    \n",
    "    def top(x):\n",
    "        # 对每条数据 ， 拆分出它的property \n",
    "        propertys=x.split(';')\n",
    "        \n",
    "        # 然后查找他所具有的property 在所有出现过的property 中的出现次数\n",
    "        cnt=[property_dict[i] for i in propertys]\n",
    "        \n",
    "        # 根据出现次数进行排序， 注意这里对性质利用的方法\n",
    "        res=sorted(zip(propertys,cnt),key=lambda x:x[1],reverse=True)\n",
    "        # top1 是其所具有的最受欢迎的property \n",
    "        top1=res[0][0]\n",
    "        # top2-10 是其所具有的最受欢迎的几个property的组合\n",
    "        top2 = '_'.join([i[0] for i in res[:2]])\n",
    "        top3 = '_'.join([i[0] for i in res[:3]])\n",
    "        top4 = '_'.join([i[0] for i in res[:4]])\n",
    "        top5='_'.join([i[0] for i in res[:5]])\n",
    "        top10 = '_'.join([i[0] for i in res[:10]])\n",
    "        return (top1,top2,top3,top4,top5,top10)\n",
    "    # 对每个类别，用他所最受欢迎的property来表示property\n",
    "    org['top']=org['item_property_list'].apply(top)\n",
    "    print('top finish')\n",
    "    org['top1']=org['top'].apply(lambda x:x[0])\n",
    "    org['top2'] = org['top'].apply(lambda x: x[1])\n",
    "    org['top3'] = org['top'].apply(lambda x: x[2])\n",
    "    org['top4'] = org['top'].apply(lambda x: x[3])\n",
    "    org['top5'] = org['top'].apply(lambda x: x[4])\n",
    "    org['top10'] = org['top'].apply(lambda x: x[5])\n",
    "    return org[['instance_id','top1','top2','top3','top4','top5','top10']]\n",
    "\n",
    "\n",
    "# property_feature(data).info()\n",
    "data=pd.merge(data,property_feature(data),on='instance_id',how='left') #拆分属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完成编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别特征全部编码\n",
    "def encode(data):\n",
    "    id_features=['shop_id', 'item_id', 'user_id', 'item_brand_id', 'item_city_id', 'user_gender_id','item_property_list', 'predict_category_property',\n",
    "                      'user_occupation_id', 'context_page_id','top1','top2','top3','top4','top5','top10','query1','query','cate']\n",
    "    for feature in id_features:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "    return data\n",
    "\n",
    "data=encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
